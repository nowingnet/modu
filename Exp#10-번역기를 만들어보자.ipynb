{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d1ac2c",
   "metadata": {},
   "source": [
    "## 번역기를 만들어보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8c491c",
   "metadata": {},
   "source": [
    "#### 라이브러리 로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dca0b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6e20a",
   "metadata": {},
   "source": [
    "#### 설정값 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff48a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "totOfSamples = 33000\n",
    "testOfSamples = 3000\n",
    "sos_token = '<sos>'\n",
    "eos_token = '<eos>'\n",
    "embedding_dim = 128\n",
    "hidden_units = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd53ff8b",
   "metadata": {},
   "source": [
    "#### 라이별 전처리 수행 \n",
    "- 소문자\n",
    "- space + 구두점 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "04e4584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accent(s):\n",
    "    # 프랑스어 악센트(accent) 삭제\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bce4540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_line(sent):\n",
    "    sent = sentence.lower().strip()\n",
    "    # 악센트 삭제 함수 호출\n",
    "    sent = remove_accent(sent)\n",
    "\n",
    "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
    "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "    sent = re.sub(r'[\" \"]+', \" \", sent)\n",
    "    \n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "\n",
    "    # 다수 개의 공백을 하나의 공백으로 치환\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e767df",
   "metadata": {},
   "source": [
    "#### 전처리 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "03ffd009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "    with open(\"data/fra.txt\", \"r\") as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "            # source 데이터 전처리\n",
    "            src_line = [w for w in preprocess_line(src_line).split()]\n",
    "\n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_line(tar_line)\n",
    "            tar_line_in = [w for w in (sos_token + \" \" + tar_line).split()]\n",
    "            tar_line_out = [w for w in (tar_line + \" \" + eos_token).split()]\n",
    "\n",
    "            encoder_input.append(src_line)\n",
    "            decoder_input.append(tar_line_in)\n",
    "            decoder_target.append(tar_line_out)\n",
    "\n",
    "            if i == totOfSamples - 1:\n",
    "                break\n",
    "\n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d9e6f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "12c9990c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n",
      "디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!']]\n",
      "디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "print('인코더의 입력 :',sents_en_in[:5])\n",
    "print('디코더의 입력 :',sents_fra_in[:5])\n",
    "print('디코더의 레이블 :',sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b228161d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go</td>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>go</td>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>go</td>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi</td>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1     2     3     4     5     6     7\n",
       "0  go  .  None  None  None  None  None  None\n",
       "1  go  .  None  None  None  None  None  None\n",
       "2  go  .  None  None  None  None  None  None\n",
       "3  go  .  None  None  None  None  None  None\n",
       "4  hi  .  None  None  None  None  None  None"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sents_en_in).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4c9ef",
   "metadata": {},
   "source": [
    "#### 토크나이징 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4a2492df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer_en = Tokenizer()\n",
    "tokenizer_en.fit_on_texts(sents_en_in)\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "\n",
    "tokenizer_fra = Tokenizer()\n",
    "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
    "\n",
    "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "\n",
    "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f99217b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>761</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2  3  4  5  6  7\n",
       "0   28  1  0  0  0  0  0  0\n",
       "1   28  1  0  0  0  0  0  0\n",
       "2   28  1  0  0  0  0  0  0\n",
       "3   28  1  0  0  0  0  0  0\n",
       "4  761  1  0  0  0  0  0  0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(encoder_input).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f10aa537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>716</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1   2   3   4   5   6   7   8   9   10  11  12  13  14  15\n",
       "0   75    8   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "1  365    1   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "2   28  512   8   3   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "3  716    8   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "4  750    8   3   0   0   0   0   0   0   0   0   0   0   0   0   0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(decoder_target).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d59429c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력의 크기(shape) : (33000, 8)\n",
      "디코더의 입력의 크기(shape) : (33000, 16)\n",
      "디코더의 레이블의 크기(shape) : (33000, 16)\n"
     ]
    }
   ],
   "source": [
    "print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n",
    "print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n",
    "print('디코더의 레이블의 크기(shape) :',decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6935b8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 최대 길이 : 8\n",
      "target 문장의 최대 길이 : 16\n"
     ]
    }
   ],
   "source": [
    "max_src_len = encoder_input.shape[1]\n",
    "max_tar_len = decoder_input.shape[1]\n",
    "print('source 문장의 최대 길이 :',max_src_len)\n",
    "print('target 문장의 최대 길이 :',max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9451e7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 4673, 프랑스어 단어 집합의 크기 : 7456\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd1306e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-testOfSamples]\n",
    "decoder_input_train = decoder_input[:-testOfSamples]\n",
    "decoder_target_train = decoder_target[:-testOfSamples]\n",
    "\n",
    "encoder_input_test = encoder_input[-testOfSamples:]\n",
    "decoder_input_test = decoder_input[-testOfSamples:]\n",
    "decoder_target_test = decoder_target[-testOfSamples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec13f52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 source 데이터의 크기 : (30000, 8)\n",
      "훈련 target 데이터의 크기 : (30000, 16)\n",
      "훈련 target 레이블의 크기 : (30000, 16)\n",
      "테스트 source 데이터의 크기 : (3000, 8)\n",
      "테스트 target 데이터의 크기 : (3000, 16)\n",
      "테스트 target 레이블의 크기 : (3000, 16)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
    "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
    "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
    "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
    "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
    "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "582e07d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs) # 임베딩 층\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
    "encoder_lstm = LSTM(hidden_units, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
    "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "276af689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(tar_vocab_size, hidden_units) # 임베딩 층\n",
    "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "\n",
    "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "\n",
    "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
    "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f73e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40512be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96e1fc7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 128)    598144      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    954368      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 128)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 128)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 128), (None, 131584      masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 128),  131584      masking_1[0][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 7456)   961824      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,777,504\n",
      "Trainable params: 2,777,504\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067507d8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4212c7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.1373 - acc: 0.9556 - val_loss: 1.2193 - val_acc: 0.8251\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.1339 - acc: 0.9564 - val_loss: 1.2216 - val_acc: 0.8247\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.1305 - acc: 0.9569 - val_loss: 1.2274 - val_acc: 0.8259\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.1268 - acc: 0.9574 - val_loss: 1.2397 - val_acc: 0.8249\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.1240 - acc: 0.9577 - val_loss: 1.2420 - val_acc: 0.8246\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.1207 - acc: 0.9584 - val_loss: 1.2481 - val_acc: 0.8266\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.1184 - acc: 0.9588 - val_loss: 1.2612 - val_acc: 0.8267\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.1160 - acc: 0.9592 - val_loss: 1.2590 - val_acc: 0.8253\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.1131 - acc: 0.9594 - val_loss: 1.2741 - val_acc: 0.8251\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.1107 - acc: 0.9599 - val_loss: 1.2719 - val_acc: 0.8262\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.1087 - acc: 0.9601 - val_loss: 1.2815 - val_acc: 0.8253\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.1068 - acc: 0.9604 - val_loss: 1.2878 - val_acc: 0.8256\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.1047 - acc: 0.9607 - val_loss: 1.2903 - val_acc: 0.8246\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.1027 - acc: 0.9610 - val_loss: 1.2967 - val_acc: 0.8257\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.1007 - acc: 0.9614 - val_loss: 1.3041 - val_acc: 0.8256\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0998 - acc: 0.9615 - val_loss: 1.3118 - val_acc: 0.8249\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0979 - acc: 0.9617 - val_loss: 1.3201 - val_acc: 0.8248\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0963 - acc: 0.9620 - val_loss: 1.3269 - val_acc: 0.8255\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0946 - acc: 0.9623 - val_loss: 1.3299 - val_acc: 0.8257\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0932 - acc: 0.9625 - val_loss: 1.3419 - val_acc: 0.8237\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0919 - acc: 0.9628 - val_loss: 1.3392 - val_acc: 0.8248\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0907 - acc: 0.9627 - val_loss: 1.3523 - val_acc: 0.8246\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0897 - acc: 0.9630 - val_loss: 1.3532 - val_acc: 0.8242\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0887 - acc: 0.9630 - val_loss: 1.3594 - val_acc: 0.8257\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0873 - acc: 0.9633 - val_loss: 1.3681 - val_acc: 0.8244\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0873 - acc: 0.9633 - val_loss: 1.3693 - val_acc: 0.8240\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0856 - acc: 0.9635 - val_loss: 1.3744 - val_acc: 0.8239\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0845 - acc: 0.9638 - val_loss: 1.3759 - val_acc: 0.8240\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0838 - acc: 0.9635 - val_loss: 1.3887 - val_acc: 0.8242\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0827 - acc: 0.9640 - val_loss: 1.3901 - val_acc: 0.8236\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0823 - acc: 0.9639 - val_loss: 1.3897 - val_acc: 0.8244\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0813 - acc: 0.9640 - val_loss: 1.3938 - val_acc: 0.8239\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0805 - acc: 0.9640 - val_loss: 1.4064 - val_acc: 0.8246\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0798 - acc: 0.9643 - val_loss: 1.4033 - val_acc: 0.8230\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0792 - acc: 0.9643 - val_loss: 1.4102 - val_acc: 0.8246\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0782 - acc: 0.9644 - val_loss: 1.4191 - val_acc: 0.8244\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0779 - acc: 0.9646 - val_loss: 1.4204 - val_acc: 0.8243\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0773 - acc: 0.9645 - val_loss: 1.4210 - val_acc: 0.8232\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0769 - acc: 0.9645 - val_loss: 1.4213 - val_acc: 0.8241\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0764 - acc: 0.9643 - val_loss: 1.4223 - val_acc: 0.8231\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0760 - acc: 0.9645 - val_loss: 1.4341 - val_acc: 0.8233\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0752 - acc: 0.9647 - val_loss: 1.4391 - val_acc: 0.8238\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0748 - acc: 0.9648 - val_loss: 1.4431 - val_acc: 0.8239\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0741 - acc: 0.9647 - val_loss: 1.4420 - val_acc: 0.8235\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0736 - acc: 0.9648 - val_loss: 1.4466 - val_acc: 0.8247\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0733 - acc: 0.9649 - val_loss: 1.4606 - val_acc: 0.8241\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0730 - acc: 0.9647 - val_loss: 1.4569 - val_acc: 0.8238\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0729 - acc: 0.9649 - val_loss: 1.4607 - val_acc: 0.8236\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0724 - acc: 0.9650 - val_loss: 1.4628 - val_acc: 0.8239\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0720 - acc: 0.9650 - val_loss: 1.4675 - val_acc: 0.8238\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7f4093",
   "metadata": {},
   "source": [
    "###### 참고: https://github.com/bamtu/Aiffel-exploration/blob/main/%5BE-10%5D%20Translation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1fe37653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history = model_history.history\n",
    "loss = history['loss']\n",
    "val_loss = history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4593ae1",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63281d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "946a2dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계 시작\n",
    "# 이전 시점의 상태를 보관할 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_units,))\n",
    "decoder_state_input_c = Input(shape=(hidden_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 훈련 때 사용했던 임베딩 층을 재사용\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "# 모든 시점에 대해서 단어 예측\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "86534144",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word\n",
    "tar_to_index = tokenizer_fra.word_index\n",
    "index_to_tar = tokenizer_fra.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c638bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "20935e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 마지막 시점의 상태(은닉 상태, 셀 상태)를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 정수 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_to_index['<sos>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 단어로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 단어를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<eos>' or\n",
    "            len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c4b23e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_src(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0):\n",
    "            sentence = sentence + index_to_src[encoded_word] + ' '\n",
    "    return sentence\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_tar(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0 and encoded_word != tar_to_index['<sos>'] and encoded_word != tar_to_index['<eos>']):\n",
    "            sentence = sentence + index_to_tar[encoded_word] + ' '\n",
    "    return sentence\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f3703b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : go . \n",
      "정답문장 : sante a \n",
      "번역문장 : on a \n",
      "--------------------------------------------------\n",
      "입력문장 : hello ! \n",
      "정답문장 : chaussures a \n",
      "번역문장 : chaussures a \n",
      "--------------------------------------------------\n",
      "입력문장 : got it ? \n",
      "정답문장 : ce tres plais ? \n",
      "번역문장 : ! ce il de ce y ? \n",
      "--------------------------------------------------\n",
      "입력문장 : hang on . \n",
      "정답문장 : savoir mal a \n",
      "번역문장 : fille . \n",
      "--------------------------------------------------\n",
      "입력문장 : here s . \n",
      "정답문장 : sors parait allumes . \n",
      "번역문장 : sors parait allumes . \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3,50,100,300,1001]:\n",
    "    input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
    "    print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
    "    print(\"번역문장 :\",decoded_sentence[1:-5])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "03c3114c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : i love a challenge . \n",
      "정답문장 : j train d l avant . \n",
      "번역문장 : j train ai parti . \n",
      "--------------------------------------------------\n",
      "입력문장 : i met an old woman . \n",
      "정답문장 : j le musique moi jouer prete . \n",
      "번역문장 : j le content moi ce ils . \n",
      "--------------------------------------------------\n",
      "입력문장 : i never got caught . \n",
      "정답문장 : je suis ca tu reste tout veut . \n",
      "번역문장 : je etes le reste evacuer . \n",
      "--------------------------------------------------\n",
      "입력문장 : i want to end this . \n",
      "정답문장 : je etais presse sur . \n",
      "번역문장 : je etais ai virez . \n",
      "--------------------------------------------------\n",
      "입력문장 : it won t last long . \n",
      "정답문장 : ! suis uds pas ok . \n",
      "번역문장 : ! suis on pas sorti . \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3, 50, 100, 300, 1001]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "    print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n",
    "    print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n",
    "    print(\"번역문장 :\",decoded_sentence[1:-5])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6a20cb",
   "metadata": {},
   "source": [
    "## 회고\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5741e6cc",
   "metadata": {},
   "source": [
    "1. 언어, 번역대상언어셋을 로드하여 전처리 과정을 거침/ 전처리 시 구두점을 단어와 분리하거나 삭제\n",
    "2. keras의 tokenizer fit_on_texts와 word_index를 사용하여 key value로 이루어진 딕셔너리를 만든다\n",
    "3. texts_to_sequences를 이용 text문장을 숫자 리스트로 변환\n",
    "4. pad_sequences를 이용하여 리스트 길이 통일 \n",
    "5. 인코더 설계, 마스킹은 패딩 토큰 숫자 0의 경우 연산제외 설정, 인코더 내부 상태 디코더로 넘겨주기위해 return_state = True 설정\n",
    "6. LSTM 은닉상태와 셀 상태를 encoder_states에 저장하고 디코더에 전달 -> 컨텍스트 벡터\n",
    "7. 디코더 인코더 마지막 은닉상태에서 초기 은닉상태 얻음, 디코더도 은닉상태, 셀상태 리턴은 하지만 훈련과정에서는 사용하지 않음\n",
    "   seq2seq에서 디코더는 각 시점마다 다중 클래스 분류 문제 풀이, 출력층은 소프트맥스와 손실함수는 크로스앤트로피 사용\n",
    "8. 원핫인코딩 하지 않은 상태 정수 레이블에 대해서 다중 클래스 분류문제 풀경우 categorical_crossentropy가 아닌 sparse_categorical_crossentropy사용\n",
    "9. 모델은 128배치로 50 에포크 수행\n",
    "10. 테스트\n",
    "  10.1 번영하고자 하는 입력문장 인코더로 입력되어 인코더 마지막 시점 은닉상태와 셀 상태 획득\n",
    "      . 인코더 입,출력으로 사용하는 encoder_inputs와 encoder_states는 훈련과정에서 이미 정의한 것들 재사용 이경우 훈련 단계에 \n",
    "      encoder_inputs와 encoder_states 사이에 있는 모든 층까지 전부 불러오게 되므로 결과적으로 훈련 단계에서 사용한 인코더를 그대로 재사용\n",
    "  10.2 인코더 은닉상태와 셀 상태, 그리고 토큰<sos>를 디코더로 보냄\n",
    "  10.3 디코더가 토큰<eos>가 나올때까지 다음 단어 예측행위 반복 \n",
    "  10.4 디코더 설계\n",
    "  10.5 decode_sequence함수 구현\n",
    "      . 문장이 입력되면 인코더는 마지막 시점까지 전개, 마지막 시점 은닉상태/셀 상태 리턴, 두 개 값 states_value에 저장\n",
    "      . 디코더 초기 입력 <SOS>준비, target_seq에 저장 while문에서 입력으로 사용 , 현재 시점 예측벡터가 output_tokens, 현재시점의 은닉상태,셀상태가 C-> 예측 벡터로 부터 현재 시점 예측 단어 target_seq얻고, h와c states_value에 저장 이를 <eos> or 번역문장이 50보다 작은 경우 반복\n",
    "    각 시점마다 번역된 단어 decoded_sentence에 누적 저장 후 최종 번역 시퀀스로 리턴 함\n",
    " 11. 각 흐름을 따라가면서 데이터/상태/변환등의 과정을 확인하여 전체 프로세스를 이해할 수 있었고 세부적인 부분도 확인이 가능하였음   \n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
